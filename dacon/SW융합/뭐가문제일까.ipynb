{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "train  = pd.read_csv('./data/train.csv')\n",
    "test  = pd.read_csv('./data/test.csv')\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop_duplicates(inplace=True, keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 값이 너무 커서 log 처리\n",
    "train['intro_log'] = np.log(train['introelapse'])\n",
    "train['test_log'] = np.log(train['testelapse'])\n",
    "train['survey_log'] = np.log(train['surveyelapse'])\n",
    "\n",
    "test['intro_log'] = np.log(test['introelapse'])\n",
    "test['test_log'] = np.log(test['testelapse'])\n",
    "test['survey_log'] = np.log(test['surveyelapse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['country', 'index'], axis=1, inplace=True)\n",
    "test.drop(['country', 'index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in train['age'].iteritems():\n",
    "    if j>100:\n",
    "        train.loc[i, 'age'] = 100\n",
    "        \n",
    "for i,j in test['age'].iteritems():\n",
    "    if j>100:\n",
    "        test.loc[i, 'age'] = 100\n",
    "        \n",
    "for i,j in train['familysize'].iteritems():\n",
    "    if j>10:\n",
    "        train.loc[i, 'familysize'] = 10\n",
    "        \n",
    "for i,j in test['familysize'].iteritems():\n",
    "    if j>10:\n",
    "        test.loc[i, 'familysize'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3513, 7731)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum().sum(), test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 7731)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum().sum(), test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 7733)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum().sum(), test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum().sum(), test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train)\n",
    "test_scaled = scaler.fit(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.loc[:, 'Q1':'ASD']\n",
    "y_train = train['nerdiness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model=RandomForestClassifier(min_samples_split=3,min_samples_leaf=1,max_depth=160,max_features='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV #하이퍼파라미터 튜닝을 위한 불러오기\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { \n",
    "    'n_estimators': [200, 500, 1000, 3000, 5000],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 150 candidates, totalling 750 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 24.7min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/c4nd0it/workspace/Machine_Running_Study/dacon/SW융합/뭐가문제일까.ipynb 셀 19\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/c4nd0it/workspace/Machine_Running_Study/dacon/SW%EC%9C%B5%ED%95%A9/%EB%AD%90%EA%B0%80%EB%AC%B8%EC%A0%9C%EC%9D%BC%EA%B9%8C.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_gs \u001b[39m=\u001b[39m GridSearchCV(rf_model, param_grid\u001b[39m=\u001b[39mparams, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/c4nd0it/workspace/Machine_Running_Study/dacon/SW%EC%9C%B5%ED%95%A9/%EB%AD%90%EA%B0%80%EB%AC%B8%EC%A0%9C%EC%9D%BC%EA%B9%8C.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model_gs\u001b[39m.\u001b[39;49mfit(x_train, y_train)\n",
      "File \u001b[0;32m~/miniforge3/envs/pycaret-env/lib/python3.8/site-packages/sklearn/utils/validation.py:72\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mPass \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m as keyword args. From version 0.25 \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39mpassing these as positional arguments will \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39mresult in an error\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(args_msg)),\n\u001b[1;32m     70\u001b[0m                   \u001b[39mFutureWarning\u001b[39;00m)\n\u001b[1;32m     71\u001b[0m kwargs\u001b[39m.\u001b[39mupdate({k: arg \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args)})\n\u001b[0;32m---> 72\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/pycaret-env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:736\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    732\u001b[0m         results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    733\u001b[0m             all_candidate_params, scorers, n_splits, all_out)\n\u001b[1;32m    734\u001b[0m         \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 736\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    738\u001b[0m \u001b[39m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[39m# best_score_ iff refit is one of the scorer names\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[39m# In single metric evaluation, refit_metric is \"score\"\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrefit \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultimetric_:\n\u001b[1;32m    742\u001b[0m     \u001b[39m# If callable, refit is expected to return the index of the best\u001b[39;00m\n\u001b[1;32m    743\u001b[0m     \u001b[39m# parameter set.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/pycaret-env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1188\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1187\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1188\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/miniforge3/envs/pycaret-env/lib/python3.8/site-packages/sklearn/model_selection/_search.py:708\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    705\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    706\u001b[0m               n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits))\n\u001b[0;32m--> 708\u001b[0m out \u001b[39m=\u001b[39m parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[1;32m    709\u001b[0m                                        X, y,\n\u001b[1;32m    710\u001b[0m                                        train\u001b[39m=\u001b[39;49mtrain, test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    711\u001b[0m                                        parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    712\u001b[0m                                        \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs)\n\u001b[1;32m    713\u001b[0m                \u001b[39mfor\u001b[39;49;00m parameters, (train, test)\n\u001b[1;32m    714\u001b[0m                \u001b[39min\u001b[39;49;00m product(candidate_params,\n\u001b[1;32m    715\u001b[0m                           cv\u001b[39m.\u001b[39;49msplit(X, y, groups)))\n\u001b[1;32m    717\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    718\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    719\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    720\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/pycaret-env/lib/python3.8/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1057\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/miniforge3/envs/pycaret-env/lib/python3.8/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    936\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/miniforge3/envs/pycaret-env/lib/python3.8/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/pycaret-env/lib/python3.8/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    437\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 439\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    441\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    442\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/miniforge3/envs/pycaret-env/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    303\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_gs = GridSearchCV(rf_model, param_grid=params, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "model_gs.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pycaret-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43d9b8981d98f08ed8bbad188c6f42989ff55edcae9d251390a9ab548565a90b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
